#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyODå¼‚å¸¸æ£€æµ‹å¯¹æ¯”å·¥å…·
ç”¨äºå¯¹æ¯”æ‰‹åŠ¨æ ‡è®°ä¸å¤šç§å¼‚å¸¸æ£€æµ‹ç®—æ³•çš„æ•ˆæœ

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-09-16
"""

import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import tkinter as tk
from tkinter import filedialog, ttk, messagebox
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import json
import threading

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

# æ£€æŸ¥å¹¶å¯¼å…¥PyOD
try:
    from pyod.models.ecod import ECOD
    from pyod.models.iforest import IForest  
    from pyod.models.pca import PCA
    from pyod.models.mcd import MCD
    from pyod.models.gmm import GMM
    PYOD_AVAILABLE = True
    print("âœ… PyODåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    PYOD_AVAILABLE = False
    print(f"âŒ PyODåº“å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·è¿è¡Œ: pip install pyod")

class XDFDataProcessor:
    """XDFæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.va_data = None
        self.manual_marks = None
        self.timestamps = None
        self.raw_data = None
        
    def load_xdf_file(self, file_path):
        """åŠ è½½XDFæ–‡ä»¶å¹¶è§£ææ•°æ®"""
        try:
            print(f"ğŸ“‚ åŠ è½½æ–‡ä»¶: {os.path.basename(file_path)}")
            
            with open(file_path, 'r', encoding='utf-8') as f:
                xdf_data = json.load(f)
            
            # é‡ç½®æ•°æ®
            self.va_data = None
            self.manual_marks = []
            self.timestamps = None
            self.raw_data = xdf_data
            
            # è§£æå„ä¸ªæ•°æ®æµ
            va_stream = None
            anomaly_stream = None
            
            for stream in xdf_data.get('streams', []):
                stream_name = stream.get('info', {}).get('name', '')
                print(f"  å‘ç°æ•°æ®æµ: {stream_name}")
                
                if 'EmotionAnalysis_VA' in stream_name:
                    va_stream = stream
                elif 'ManualAnomalyMarks' in stream_name:
                    anomaly_stream = stream
            
            # è§£æVAæ•°æ®
            if va_stream:
                success = self.parse_va_data(va_stream)
                if not success:
                    return False
            else:
                print("âŒ æœªæ‰¾åˆ°VAæ•°æ®æµ")
                return False
            
            # è§£æå¼‚å¸¸æ ‡è®°
            if anomaly_stream:
                self.parse_anomaly_marks(anomaly_stream)
                print(f"âœ… æ‰¾åˆ° {len(self.manual_marks)} ä¸ªæ‰‹åŠ¨å¼‚å¸¸æ ‡è®°")
            else:
                print("â„¹ï¸ æœªæ‰¾åˆ°æ‰‹åŠ¨å¼‚å¸¸æ ‡è®°æ•°æ®æµ")
                
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½XDFæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def parse_va_data(self, stream):
        """è§£æVAæ•°æ®"""
        try:
            time_series = stream.get('time_series', [])
            timestamps = stream.get('time_stamps', [])
            
            if len(time_series) == 0:
                print("âŒ VAæ•°æ®æµä¸ºç©º")
                return False
            
            print(f"  VAæ•°æ®ç‚¹: {len(time_series)}")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            data = np.array(time_series)
            timestamps = np.array(timestamps)
            
            # å¤„ç†æ•°æ®æ ¼å¼ - å‡è®¾æ ¼å¼ï¼š[valence, arousal, face_detected]
            if data.shape[1] >= 2:
                self.va_data = data[:, :2]  # åªå–valenceå’Œarousal
                self.timestamps = timestamps
                
                # è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆNaNæˆ–æ— äººè„¸çš„æ•°æ®ç‚¹ï¼‰
                if data.shape[1] >= 3:
                    face_detected = data[:, 2] > 0.5
                    valid_mask = face_detected & np.isfinite(self.va_data[:, 0]) & np.isfinite(self.va_data[:, 1])
                else:
                    valid_mask = np.isfinite(self.va_data[:, 0]) & np.isfinite(self.va_data[:, 1])
                
                self.va_data = self.va_data[valid_mask]
                self.timestamps = self.timestamps[valid_mask]
                
                print(f"  æœ‰æ•ˆVAæ•°æ®ç‚¹: {len(self.va_data)}")
                print(f"  æ—¶é—´èŒƒå›´: {self.timestamps[0]:.2f} - {self.timestamps[-1]:.2f}ç§’")
                
                return True
            else:
                print(f"âŒ VAæ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼ŒæœŸæœ›è‡³å°‘2åˆ—ï¼Œå®é™…{data.shape[1]}åˆ—")
                return False
                
        except Exception as e:
            print(f"âŒ è§£æVAæ•°æ®å¤±è´¥: {e}")
            return False
    
    def parse_anomaly_marks(self, stream):
        """è§£ææ‰‹åŠ¨å¼‚å¸¸æ ‡è®°"""
        try:
            time_series = stream.get('time_series', [])
            timestamps = stream.get('time_stamps', [])
            
            # æ‰¾åˆ°æ ‡è®°ä¸ºå¼‚å¸¸çš„æ—¶é—´ç‚¹
            anomaly_times = []
            for i, mark in enumerate(time_series):
                if len(mark) > 0 and mark[0] == 1:  # å¼‚å¸¸æ ‡è®°
                    anomaly_times.append(timestamps[i])
            
            self.manual_marks = np.array(anomaly_times)
            print(f"  è§£æåˆ° {len(self.manual_marks)} ä¸ªå¼‚å¸¸æ ‡è®°")
            
        except Exception as e:
            print(f"âŒ è§£æå¼‚å¸¸æ ‡è®°å¤±è´¥: {e}")
            self.manual_marks = np.array([])
    
    def extract_features(self):
        """ç‰¹å¾å·¥ç¨‹"""
        if self.va_data is None or len(self.va_data) == 0:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„VAæ•°æ®è¿›è¡Œç‰¹å¾æå–")
            return None
            
        try:
            features = []
            
            # åŸå§‹VAå€¼
            valence = self.va_data[:, 0]
            arousal = self.va_data[:, 1]
            features.extend([valence, arousal])
            
            # ç§»åŠ¨å¹³å‡ï¼ˆçª—å£=5ï¼‰
            window = 5
            if len(valence) >= window:
                v_ma = np.convolve(valence, np.ones(window)/window, mode='same')
                a_ma = np.convolve(arousal, np.ones(window)/window, mode='same')
                features.extend([v_ma, a_ma])
            
            # å˜åŒ–ç‡
            v_diff = np.gradient(valence)
            a_diff = np.gradient(arousal)
            features.extend([v_diff, a_diff])
            
            # å¹…åº¦ï¼ˆè·ç¦»åŸç‚¹çš„è·ç¦»ï¼‰
            magnitude = np.sqrt(valence**2 + arousal**2)
            features.append(magnitude)
            
            # å˜åŒ–å¹…åº¦
            magnitude_diff = np.gradient(magnitude)
            features.append(magnitude_diff)
            
            # ç»„åˆç‰¹å¾çŸ©é˜µ
            feature_matrix = np.column_stack(features)
            
            # æ£€æŸ¥å¹¶å¤„ç†æ— ç©·å€¼å’ŒNaN
            feature_matrix = np.nan_to_num(feature_matrix, nan=0.0, posinf=0.0, neginf=0.0)
            
            print(f"âœ… ç‰¹å¾æå–å®Œæˆ: {feature_matrix.shape[0]}è¡Œ x {feature_matrix.shape[1]}åˆ—")
            return feature_matrix
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
            return None

class AnomalyDetectionSuite:
    """å¼‚å¸¸æ£€æµ‹ç®—æ³•å¥—ä»¶"""
    
    def __init__(self, contamination=0.1):
        if not PYOD_AVAILABLE:
            self.algorithms = {}
            return
            
        # ä½¿ç”¨é€‚å½“çš„contaminationå‚æ•°æ¥ç¡®ä¿èƒ½æ£€æµ‹åˆ°å¼‚å¸¸
        self.contamination = contamination
        self.algorithms = {
            'ECOD': ECOD(contamination=contamination),
            'IsolationForest': IForest(contamination=contamination, n_estimators=100, random_state=42),
            'PCA': PCA(contamination=contamination, random_state=42), 
            'MCD': MCD(contamination=contamination, random_state=42),
            'GMM': GMM(contamination=contamination, n_components=2, random_state=42)
        }
        self.results = {}
        print(f"âœ… åˆå§‹åŒ–äº† {len(self.algorithms)} ä¸ªå¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼ˆcontamination={contamination}ï¼‰")
    
    def run_all_algorithms(self, features):
        """è¿è¡Œæ‰€æœ‰å¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼Œå‚è€ƒbatch_test_all_algorithms.pyçš„æ–¹å¼"""
        if not PYOD_AVAILABLE:
            print("âŒ PyODä¸å¯ç”¨ï¼Œæ— æ³•è¿è¡Œå¼‚å¸¸æ£€æµ‹")
            return {}
            
        results = {}
        
        print("\nğŸ” å¼€å§‹è¿è¡Œå¼‚å¸¸æ£€æµ‹ç®—æ³•...")
        
        # æ ‡å‡†åŒ–æ•°æ®ï¼ˆé‡è¦ï¼ï¼‰
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(features)
        
        for name, algorithm in self.algorithms.items():
            print(f"  è¿è¡Œ {name}...")
            start_time = time.time()
            
            try:
                # è®­ç»ƒæ¨¡å‹
                algorithm.fit(X_scaled)
                
                # é¢„æµ‹å¼‚å¸¸ç‚¹
                predictions = algorithm.predict(X_scaled)  # 0: normal, 1: anomaly
                anomaly_scores = algorithm.decision_function(X_scaled)  # å¼‚å¸¸åˆ†æ•°
                
                execution_time = time.time() - start_time
                
                # æ‰¾åˆ°å¼‚å¸¸ç‚¹çš„ç´¢å¼•
                anomaly_indices = np.where(predictions == 1)[0]
                
                results[name] = {
                    'predictions': predictions,
                    'scores': anomaly_scores,
                    'anomaly_indices': anomaly_indices,
                    'execution_time': execution_time,
                    'total_anomalies_detected': len(anomaly_indices)
                }
                
                print(f"    âœ… å®Œæˆï¼šæ£€æµ‹åˆ° {len(anomaly_indices)} ä¸ªå¼‚å¸¸ç‚¹ï¼Œè€—æ—¶ {execution_time:.3f}ç§’")
                
            except Exception as e:
                print(f"    âŒ å¤±è´¥ï¼š{e}")
                results[name] = {
                    'predictions': np.zeros(len(features)),
                    'scores': np.zeros(len(features)),
                    'anomaly_indices': [],
                    'execution_time': 0,
                    'total_anomalies_detected': 0,
                    'error': str(e)
                }
        
        self.results = results
        return results

class VisualizationGenerator:
    """å¯è§†åŒ–ç”Ÿæˆå™¨ - ç”Ÿæˆç±»ä¼¼batch_test_all_algorithms.pyçš„å›¾è¡¨"""
    
    def __init__(self):
        self.plt_available = False
        try:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('TkAgg')  # ä½¿ç”¨TkAggåç«¯
            self.plt = plt
            self.plt_available = True
            
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            import matplotlib.pyplot as plt
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False
            
        except ImportError:
            print("âš ï¸ matplotlibæœªå®‰è£…ï¼Œå°†è·³è¿‡å¯è§†åŒ–")
    
    def plot_single_algorithm_result(self, algorithm_name, va_data, timestamps, 
                                   predictions, scores, manual_marks, 
                                   detected_anomalies, hit_rate):
        """ç»˜åˆ¶å•ä¸ªç®—æ³•çš„æ£€æµ‹ç»“æœ - æŒ‰ç…§å‚è€ƒå›¾ç‰‡æ ¼å¼"""
        if not self.plt_available:
            return None
            
        try:
            fig, (ax1, ax2) = self.plt.subplots(2, 1, figsize=(15, 10))
            fig.suptitle(f'{algorithm_name} å¼‚å¸¸æ£€æµ‹ç»“æœå¯¹æ¯”', fontsize=16, fontweight='bold')
            
            # ä¸Šå›¾ï¼šVAæ•°æ®æ—¶é—´åºåˆ—ï¼ˆç±»ä¼¼GSRæ•°æ®ï¼‰
            # åªç»˜åˆ¶Valenceæ•°æ®ä½œä¸ºä¸»è¦ä¿¡å·ï¼ˆç±»ä¼¼GSRï¼‰
            ax1.plot(timestamps, va_data[:, 0], 'b-', alpha=0.8, linewidth=1.5, label='Valence')
            
            # æ ‡è®°æ‰‹åŠ¨å¼‚å¸¸ç‚¹ - ç»¿è‰²æ–¹å—ï¼ˆå‚è€ƒå›¾ç‰‡é£æ ¼ï¼‰
            if len(manual_marks) > 0:
                manual_y_positions = []
                for mark_time in manual_marks:
                    # æ‰¾åˆ°æœ€æ¥è¿‘çš„æ—¶é—´ç‚¹ç´¢å¼•
                    closest_idx = np.argmin(np.abs(timestamps - mark_time))
                    if closest_idx < len(va_data):
                        y_pos = va_data[closest_idx, 0]  # Valenceå€¼
                        manual_y_positions.append(y_pos)
                        ax1.scatter([mark_time], [y_pos], 
                                  c='green', s=100, marker='s', 
                                  label='æ‰‹åŠ¨æ ‡æ³¨å¼‚å¸¸ç‚¹' if mark_time == manual_marks[0] else "", 
                                  zorder=10, edgecolors='darkgreen', linewidth=1)
            
            # æ ‡è®°æ£€æµ‹åˆ°çš„å¼‚å¸¸ç‚¹ - çº¢è‰²åœ†ç‚¹ï¼ˆå‚è€ƒå›¾ç‰‡é£æ ¼ï¼‰
            if len(detected_anomalies) > 0:
                valid_anomalies = [idx for idx in detected_anomalies if 0 <= idx < len(timestamps)]
                if valid_anomalies:
                    detected_times = timestamps[valid_anomalies]
                    detected_y_positions = va_data[valid_anomalies, 0]  # Valenceå€¼
                    ax1.scatter(detected_times, detected_y_positions, 
                              c='red', s=60, marker='o', alpha=0.8,
                              label='ç®—æ³•æ£€æµ‹å¼‚å¸¸ç‚¹', zorder=8, edgecolors='darkred', linewidth=1)
            
            ax1.set_xlabel('Time Index', fontsize=12)
            ax1.set_ylabel('VA (Valence)', fontsize=12)
            ax1.set_title(f'VAæ•°æ®: æ‰‹åŠ¨æ ‡æ³¨ vs {algorithm_name}æ£€æµ‹ç»“æœå¯¹æ¯”\nå‘½ä¸­æƒ…å†µ: {hit_rate:.1f}%', fontsize=14)
            ax1.legend(loc='upper right', fontsize=10)
            ax1.grid(True, alpha=0.3)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†ï¼ˆå‚è€ƒå›¾ç‰‡é£æ ¼ï¼‰- ä¿®æ­£æ˜¾ç¤º
            hit_count = int(round(hit_rate * len(manual_marks) / 100))
            info_text = f'å‘½ä¸­æƒ…å†µ: {hit_count}/{len(manual_marks)} = {hit_rate:.1f}%'
            ax1.text(0.02, 0.95, info_text, transform=ax1.transAxes, 
                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),
                    fontsize=10, verticalalignment='top')
            
            # ä¸‹å›¾ï¼šå¼‚å¸¸åˆ†æ•°æ—¶é—´åºåˆ—ï¼ˆå‚è€ƒå›¾ç‰‡çš„COPOD Anomaly Scoresé£æ ¼ï¼‰
            ax2.plot(timestamps, scores, color='purple', alpha=0.7, linewidth=1.5, label='å¼‚å¸¸åˆ†æ•°')
            
            # åœ¨å¼‚å¸¸åˆ†æ•°å›¾ä¸Šæ ‡è®°æ‰‹åŠ¨å¼‚å¸¸ç‚¹ - ç»¿è‰²æ–¹å—
            if len(manual_marks) > 0:
                for mark_time in manual_marks:
                    closest_idx = np.argmin(np.abs(timestamps - mark_time))
                    if closest_idx < len(scores):
                        y_pos = scores[closest_idx]
                        ax2.scatter([mark_time], [y_pos], 
                                  c='green', s=100, marker='s', 
                                  label='æ‰‹åŠ¨æ ‡æ³¨çš„å¼‚å¸¸åˆ†æ•°' if mark_time == manual_marks[0] else "", 
                                  zorder=10, edgecolors='darkgreen', linewidth=1)
            
            # æ ‡è®°ç®—æ³•æ£€æµ‹çš„å¼‚å¸¸åˆ†æ•° - çº¢è‰²åœ†ç‚¹
            if len(detected_anomalies) > 0:
                valid_anomalies = [idx for idx in detected_anomalies if 0 <= idx < len(timestamps) and 0 <= idx < len(scores)]
                if valid_anomalies:
                    detected_times = timestamps[valid_anomalies]
                    valid_scores = scores[valid_anomalies]
                    ax2.scatter(detected_times, valid_scores, 
                               c='red', s=60, marker='o', alpha=0.8,
                               label='æ£€æµ‹å¼‚å¸¸åˆ†æ•°', zorder=8, edgecolors='darkred', linewidth=1)
            
            ax2.set_xlabel('Time Index', fontsize=12)
            ax2.set_ylabel('Anomaly Score', fontsize=12)
            ax2.set_title(f'{algorithm_name} å¼‚å¸¸åˆ†æ•°', fontsize=14)
            ax2.legend(loc='upper right', fontsize=10)
            ax2.grid(True, alpha=0.3)
            
            # æ·»åŠ å›¾ä¾‹ä¿¡æ¯ï¼ˆå‚è€ƒå›¾ç‰‡å³ä¾§çš„å›¾ä¾‹é£æ ¼ï¼‰
            legend_elements = [
                self.plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='green', 
                               markersize=8, label=f'æ‰‹åŠ¨æ ‡æ³¨å¼‚å¸¸ç‚¹ ({len(manual_marks)})'),
                self.plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', 
                               markersize=6, label=f'ç®—æ³•æ£€æµ‹å¼‚å¸¸ç‚¹ ({len(detected_anomalies)})'),
                self.plt.Line2D([0], [0], color='blue', linewidth=2, label='Valenceæ•°æ®'),
                self.plt.Line2D([0], [0], color='purple', linewidth=2, label='å¼‚å¸¸åˆ†æ•°')
            ]
            
            # åœ¨å›¾çš„å³ä¾§æ·»åŠ ç»Ÿä¸€å›¾ä¾‹
            fig.legend(handles=legend_elements, loc='center right', bbox_to_anchor=(0.98, 0.5), fontsize=10)
            
            self.plt.tight_layout()
            self.plt.subplots_adjust(right=0.85)  # ä¸ºå³ä¾§å›¾ä¾‹ç•™ç©ºé—´
            return fig
            
        except Exception as e:
            print(f"âš ï¸ ç»˜å›¾å¤±è´¥: {e}")
            return None
    
    def plot_algorithms_comparison(self, all_results, manual_marks_count):
        """ç»˜åˆ¶æ‰€æœ‰ç®—æ³•å¯¹æ¯”å›¾è¡¨"""
        if not self.plt_available:
            return None
            
        try:
            # æå–ç®—æ³•æ€§èƒ½æ•°æ®
            algorithms = []
            hit_rates = []
            execution_times = []
            detected_counts = []
            
            for name, result in all_results.items():
                if 'error' not in result:
                    algorithms.append(name)
                    hit_rates.append(result.get('hit_rate', 0))
                    execution_times.append(result.get('execution_time', 0))
                    detected_counts.append(result.get('detected_anomalies', 0))
            
            if not algorithms:
                return None
            
            # åˆ›å»º2x2å­å›¾
            fig, ((ax1, ax2), (ax3, ax4)) = self.plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('PyODç®—æ³•ç»¼åˆæ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')
            
            colors = self.plt.cm.Set3(np.linspace(0, 1, len(algorithms)))
            
            # 1. å‘½ä¸­ç‡å¯¹æ¯”
            bars1 = ax1.barh(algorithms, hit_rates, color=colors, alpha=0.8)
            ax1.set_title('å‘½ä¸­ç‡å¯¹æ¯” (%)', fontweight='bold')
            ax1.set_xlabel('å‘½ä¸­ç‡ (%)')
            ax1.grid(True, alpha=0.3)
            
            for i, (bar, value) in enumerate(zip(bars1, hit_rates)):
                ax1.text(value + 1, bar.get_y() + bar.get_height()/2, 
                        f'{value:.1f}%', ha='left', va='center', fontweight='bold')
            
            # 2. æ£€æµ‹å¼‚å¸¸ç‚¹æ•°å¯¹æ¯”
            bars2 = ax2.barh(algorithms, detected_counts, color=colors, alpha=0.8)
            ax2.set_title('æ£€æµ‹å¼‚å¸¸ç‚¹æ•°', fontweight='bold')
            ax2.set_xlabel('æ£€æµ‹æ•°é‡')
            ax2.grid(True, alpha=0.3)
            
            for i, (bar, value) in enumerate(zip(bars2, detected_counts)):
                ax2.text(value + 0.1, bar.get_y() + bar.get_height()/2, 
                        str(int(value)), ha='left', va='center', fontweight='bold')
            
            # 3. æ‰§è¡Œæ—¶é—´å¯¹æ¯”
            bars3 = ax3.barh(algorithms, execution_times, color=colors, alpha=0.8)
            ax3.set_title('æ‰§è¡Œæ—¶é—´å¯¹æ¯” (ç§’)', fontweight='bold')
            ax3.set_xlabel('æ—¶é—´ (ç§’)')
            ax3.grid(True, alpha=0.3)
            
            for i, (bar, value) in enumerate(zip(bars3, execution_times)):
                ax3.text(value + 0.001, bar.get_y() + bar.get_height()/2, 
                        f'{value:.3f}s', ha='left', va='center', fontweight='bold')
            
            # 4. ç®—æ³•æ’åæ€»ç»“
            ax4.axis('off')
            ranking_text = f"ğŸ“Š æ€§èƒ½æ€»ç»“ (æ‰‹åŠ¨æ ‡è®°: {manual_marks_count}ä¸ª)\n\n"
            
            # æŒ‰å‘½ä¸­ç‡æ’åº
            sorted_indices = np.argsort(hit_rates)[::-1]
            ranking_text += "ğŸ† å‘½ä¸­ç‡æ’å:\n"
            for i, idx in enumerate(sorted_indices[:5]):
                emoji = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "ğŸ…", "ğŸ…"][i]
                ranking_text += f"{emoji} {algorithms[idx]}: {hit_rates[idx]:.1f}%\n"
            
            ranking_text += "\nâš¡ é€Ÿåº¦æ’å:\n"
            speed_indices = np.argsort(execution_times)
            for i, idx in enumerate(speed_indices[:5]):
                emoji = ["ğŸš€", "âš¡", "ğŸƒ", "ğŸš¶", "ğŸš¶"][i]
                ranking_text += f"{emoji} {algorithms[idx]}: {execution_times[idx]:.3f}s\n"
            
            ax4.text(0.1, 0.9, ranking_text, transform=ax4.transAxes, fontsize=12,
                    verticalalignment='top', fontfamily='monospace')
            
            self.plt.tight_layout()
            return fig
            
        except Exception as e:
            print(f"âš ï¸ å¯¹æ¯”å›¾ç»˜åˆ¶å¤±è´¥: {e}")
            return None


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨ - ç”Ÿæˆç±»ä¼¼å›¾ç‰‡ä¸­çš„æŠ¥å‘Šæ ¼å¼"""
    
    def __init__(self):
        self.report_data = {}
    
    def generate_individual_report(self, algorithm_name, predictions, scores, manual_marks, 
                                 timestamps, execution_time, hit_rate, precision, recall, f1):
        """ç”Ÿæˆå•ä¸ªç®—æ³•çš„è¯¦ç»†æŠ¥å‘Šï¼ˆç±»ä¼¼å›¾1æ ¼å¼ï¼‰"""
        
        report = f"""
{'='*80}
{algorithm_name} å¼‚å¸¸æ£€æµ‹è¯¦ç»†æŠ¥å‘Š
{'='*80}

ğŸ“Š æ£€æµ‹æ¦‚è¦:
- ç®—æ³•åç§°: {algorithm_name}
- æ€»æ•°æ®ç‚¹: {len(predictions)}
- æ£€æµ‹åˆ°å¼‚å¸¸ç‚¹: {np.sum(predictions)}
- æ‰‹åŠ¨æ ‡è®°å¼‚å¸¸ç‚¹: {len(manual_marks)}
- æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’

ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:
- å‘½ä¸­ç‡ (Hit Rate): {hit_rate:.1f}% ({int(hit_rate * len(manual_marks) / 100)}/{len(manual_marks)})
- ç²¾ç¡®ç‡ (Precision): {precision:.3f}
- å¬å›ç‡ (Recall): {recall:.3f}
- F1åˆ†æ•°: {f1:.3f}

ğŸ¯ å¼‚å¸¸ç‚¹è¯¦æƒ…:
"""
        
        # æ‰¾åˆ°æ£€æµ‹åˆ°çš„å¼‚å¸¸ç‚¹
        try:
            if predictions is not None and len(predictions) > 0:
                anomaly_indices = np.where(predictions == 1)[0]
            else:
                anomaly_indices = []
        except Exception as e:
            print(f"âš ï¸ å¤„ç†é¢„æµ‹ç»“æœæ—¶å‡ºé”™: {e}")
            anomaly_indices = []
        
        if len(anomaly_indices) > 0:
            report += "æ£€æµ‹åˆ°çš„å¼‚å¸¸ç‚¹æ—¶é—´æˆ³:\n"
            for i, idx in enumerate(anomaly_indices):
                timestamp = timestamps[idx] if idx < len(timestamps) else 0
                score = scores[idx] if idx < len(scores) else 0
                
                # æ£€æŸ¥æ˜¯å¦å‘½ä¸­æ‰‹åŠ¨æ ‡è®°
                hit = "âœ…" if self.is_hit(timestamp, manual_marks) else "âŒ"
                
                report += f"  {i+1:3d}. æ—¶é—´: {timestamp:8.2f}s, å¼‚å¸¸åˆ†æ•°: {score:.3f} {hit}\n"
                
                if i >= 20:  # é™åˆ¶æ˜¾ç¤ºå‰20ä¸ª
                    report += f"  ... è¿˜æœ‰ {len(anomaly_indices) - 20} ä¸ªå¼‚å¸¸ç‚¹\n"
                    break
        else:
            report += "æœªæ£€æµ‹åˆ°å¼‚å¸¸ç‚¹\n"
        
        report += f"\n{'='*80}\n"
        return report
    
    def generate_comparison_report(self, all_results, manual_marks):
        """ç”Ÿæˆæ‰€æœ‰ç®—æ³•å¯¹æ¯”æŠ¥å‘Šï¼ˆç±»ä¼¼å›¾2æ ¼å¼ï¼‰"""
        
        report = f"""
{'='*80}
åˆå¹¶æ•°æ®é›†PyODç®—æ³•æ€§èƒ½å¯¹æ¯” (æ€»æ ‡æ³¨å¼‚å¸¸: {len(manual_marks)}ä¸ª, å®¹å·®: Â±1ç§’)
{'='*80}

ç®—æ³•æ£€æµ‹å¬å›ç‡:
"""
        
        # æ”¶é›†æ‰€æœ‰ç®—æ³•çš„ç»“æœ
        algorithm_stats = []
        
        for name, result in all_results.items():
            hit_rate = result.get('hit_rate', 0)
            execution_time = result.get('execution_time', 0)
            detected_count = result.get('detected_anomalies', 0)
            
            algorithm_stats.append({
                'name': name,
                'hit_rate': hit_rate,
                'execution_time': execution_time,
                'detected_count': detected_count,
                'hit_count': int(hit_rate * len(manual_marks) / 100)
            })
        
        # æŒ‰å‘½ä¸­ç‡æ’åº
        algorithm_stats.sort(key=lambda x: x['hit_rate'], reverse=True)
        
        # ç”Ÿæˆå¬å›ç‡æŠ¥å‘Š
        for i, stat in enumerate(algorithm_stats):
            report += f"{stat['name']:<12} {stat['hit_count']}/{len(manual_marks)}\n"
        
        report += f"\nç®—æ³•è®­ç»ƒæ—¶é—´:\n"
        
        # ç”Ÿæˆè®­ç»ƒæ—¶é—´æŠ¥å‘Š
        for stat in algorithm_stats:
            if stat['execution_time'] < 0.001:
                time_str = f"{stat['execution_time']*1000:.1f}ms"
            elif stat['execution_time'] < 1:
                time_str = f"{stat['execution_time']*1000:.0f}ms"
            else:
                time_str = f"{stat['execution_time']:.2f}s"
            
            report += f"{stat['name']:<12} {time_str}\n"
        
        report += f"\n{'='*80}\n"
        report += "ğŸ“ˆ æ€§èƒ½æ’å (æŒ‰å‘½ä¸­ç‡):\n"
        
        for i, stat in enumerate(algorithm_stats):
            emoji = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i] if i < 3 else "ğŸ…"
            report += f"{emoji} {i+1}. {stat['name']}: {stat['hit_rate']:.1f}% ({stat['hit_count']}/{len(manual_marks)})\n"
        
        report += f"\nâš¡ é€Ÿåº¦æ’å (æŒ‰æ‰§è¡Œæ—¶é—´):\n"
        
        # æŒ‰é€Ÿåº¦æ’åº
        speed_stats = sorted(algorithm_stats, key=lambda x: x['execution_time'])
        for i, stat in enumerate(speed_stats):
            emoji = ["ğŸš€", "âš¡", "ğŸƒ"][i] if i < 3 else "ğŸš¶"
            if stat['execution_time'] < 0.001:
                time_str = f"{stat['execution_time']*1000:.1f}ms"
            elif stat['execution_time'] < 1:
                time_str = f"{stat['execution_time']*1000:.0f}ms"
            else:
                time_str = f"{stat['execution_time']:.2f}s"
            report += f"{emoji} {i+1}. {stat['name']}: {time_str}\n"
        
        report += f"\n{'='*80}\n"
        return report
    
    def is_hit(self, detected_time, manual_marks, tolerance=1.0):
        """æ£€æŸ¥æ£€æµ‹ç‚¹æ˜¯å¦å‘½ä¸­æ‰‹åŠ¨æ ‡è®°ï¼ˆÂ±1ç§’å®¹å·®ï¼‰"""
        if len(manual_marks) == 0:
            return False
        
        distances = np.abs(manual_marks - detected_time)
        return np.any(distances <= tolerance)


class ComparisonAnalyzer:
    """ç»“æœå¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        pass
    
    def calculate_hit_rate(self, predicted_anomaly_indices, manual_mark_times, timestamps, tolerance=1.0):
        """è®¡ç®—å‘½ä¸­ç‡"""
        if len(manual_mark_times) == 0:
            return 0.0, 0, 0, []
        
        # è·å–é¢„æµ‹å¼‚å¸¸çš„æ—¶é—´æˆ³
        predicted_times = []
        for idx in predicted_anomaly_indices:
            if idx < len(timestamps):
                predicted_times.append(timestamps[idx])
        
        hits = 0
        hit_details = []
        
        for mark_time in manual_mark_times:
            # åœ¨å®¹å·®èŒƒå›´å†…æŸ¥æ‰¾é¢„æµ‹çš„å¼‚å¸¸ç‚¹
            found_hit = False
            closest_time = None
            closest_diff = float('inf')
            
            for idx in predicted_anomaly_indices:
                if idx < len(timestamps):
                    pred_time = timestamps[idx]
                    time_diff = abs(pred_time - mark_time)
                    
                    # è®°å½•æœ€æ¥è¿‘çš„é¢„æµ‹æ—¶é—´
                    if time_diff < closest_diff:
                        closest_diff = time_diff
                        closest_time = pred_time
                    
                    if time_diff <= tolerance:
                        hits += 1
                        hit_details.append({
                            'manual_time': mark_time,
                            'predicted_time': pred_time,
                            'time_diff': time_diff
                        })
                        found_hit = True
                        break
            
            if not found_hit:
                hit_details.append({
                    'manual_time': mark_time,
                    'predicted_time': None,
                    'time_diff': None
                })
                if closest_time:
                    pass  # å¯é€‰ï¼šè®°å½•æœ€æ¥è¿‘çš„é¢„æµ‹æ—¶é—´æ—¥å¿—
        
        hit_rate = (hits / len(manual_mark_times)) * 100
        
        return hit_rate, hits, len(manual_mark_times), hit_details
    
    def generate_comparison_report(self, detection_results, manual_marks, timestamps):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        report = {
            'summary': {
                'total_manual_marks': len(manual_marks),
                'timestamp_range': f"{timestamps[0]:.2f} - {timestamps[-1]:.2f}s" if len(timestamps) > 0 else "N/A",
                'data_points': len(timestamps)
            },
            'algorithms': {}
        }
        
        for alg_name, result in detection_results.items():
            if result is None or 'error' in result:
                continue
                
            # æ‰¾åˆ°é¢„æµ‹ä¸ºå¼‚å¸¸çš„ç‚¹
            anomaly_indices = np.where(result['predictions'] == 1)[0]
            
            # è®¡ç®—å‘½ä¸­ç‡
            hit_rate, hits, total_marks, hit_details = self.calculate_hit_rate(
                anomaly_indices, manual_marks, timestamps
            )
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡
            total_predictions = len(anomaly_indices)
            precision = hits / total_predictions if total_predictions > 0 else 0
            recall = hit_rate  # ç­‰åŒäºå‘½ä¸­ç‡
            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            report['algorithms'][alg_name] = {
                'execution_time': result['execution_time'],
                'total_anomalies_detected': total_predictions,
                'manual_marks_hit': hits,
                'hit_rate': hit_rate,
                'precision': precision,
                'recall': recall,
                'f1_score': f1_score,
                'hit_details': hit_details,
                # ä¿å­˜åŸå§‹æ£€æµ‹ç»“æœç”¨äºå¯è§†åŒ–
                'predictions': result['predictions'],
                'scores': result['scores'],
                'anomaly_indices': anomaly_indices
            }
        
        return report

class PyODAnomalyGUI:
    """å›¾å½¢ç”¨æˆ·ç•Œé¢"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("PyODå¼‚å¸¸æ£€æµ‹å¯¹æ¯”å·¥å…· v1.0")
        self.root.geometry("1400x900")
        
        # è®¾ç½®å›¾æ ‡å’Œæ ·å¼
        try:
            self.root.iconbitmap(default="")  # å¯ä»¥æ·»åŠ å›¾æ ‡æ–‡ä»¶
        except:
            pass
        
        self.xdf_files = []
        self.processor = XDFDataProcessor()
        self.detector = AnomalyDetectionSuite()
        self.analyzer = ComparisonAnalyzer()
        self.visualizer = VisualizationGenerator()  # æ–°å¢å¯è§†åŒ–å™¨
        self.all_reports = []
        
        # æ£€æŸ¥PyODå¯ç”¨æ€§
        if not PYOD_AVAILABLE:
            messagebox.showerror("é”™è¯¯", "PyODåº“æœªå®‰è£…ï¼\n\nè¯·è¿è¡Œ: pip install pyod")
        
        self.setup_ui()
    
    def setup_ui(self):
        """è®¾ç½®ç•Œé¢"""
        # åˆ›å»ºæ ·å¼
        style = ttk.Style()
        style.theme_use('clam')
        
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # æ ‡é¢˜
        title_label = ttk.Label(main_frame, text="PyODå¼‚å¸¸æ£€æµ‹å¯¹æ¯”å·¥å…·", font=('Arial', 16, 'bold'))
        title_label.pack(pady=(0, 10))
        
        # æ–‡ä»¶é€‰æ‹©åŒºåŸŸ
        file_frame = ttk.LabelFrame(main_frame, text="ğŸ“ XDFæ–‡ä»¶é€‰æ‹©")
        file_frame.pack(fill=tk.X, pady=(0, 10))
        
        file_buttons_frame = ttk.Frame(file_frame)
        file_buttons_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Button(file_buttons_frame, text="é€‰æ‹©XDFæ–‡ä»¶", command=self.select_files).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(file_buttons_frame, text="æ¸…ç©ºåˆ—è¡¨", command=self.clear_files).pack(side=tk.LEFT)
        
        self.file_label = ttk.Label(file_frame, text="æœªé€‰æ‹©æ–‡ä»¶", foreground="gray")
        self.file_label.pack(anchor=tk.W, padx=5, pady=(0, 5))
        
        # å‚æ•°è®¾ç½®åŒºåŸŸ
        param_frame = ttk.LabelFrame(main_frame, text="âš™ï¸ å‚æ•°è®¾ç½®")
        param_frame.pack(fill=tk.X, pady=(0, 10))
        
        param_inner_frame = ttk.Frame(param_frame)
        param_inner_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(param_inner_frame, text="å®¹å·®æ—¶é—´(ç§’):").pack(side=tk.LEFT)
        self.tolerance_var = tk.DoubleVar(value=1.0)
        tolerance_spinbox = ttk.Spinbox(param_inner_frame, from_=0.1, to=5.0, increment=0.1, 
                                       textvariable=self.tolerance_var, width=10)
        tolerance_spinbox.pack(side=tk.LEFT, padx=(5, 20))
        
        ttk.Label(param_inner_frame, text="(ä½¿ç”¨ç®—æ³•é»˜è®¤å‚æ•°)", foreground="gray").pack(side=tk.LEFT)
        
        # æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill=tk.X, pady=(0, 10))
        
        # å·¦ä¾§æŒ‰é’®
        left_buttons = ttk.Frame(control_frame)
        left_buttons.pack(side=tk.LEFT)
        
        self.run_button = ttk.Button(left_buttons, text="ğŸš€ è¿è¡Œå¼‚å¸¸æ£€æµ‹", command=self.run_detection_threaded)
        self.run_button.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(left_buttons, text="ğŸ“Š å¯¼å‡ºæŠ¥å‘Š", command=self.export_report).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(left_buttons, text="ğŸ”„ é‡ç½®", command=self.reset_all).pack(side=tk.LEFT)
        
        # å³ä¾§è¿›åº¦æ¡
        progress_frame = ttk.Frame(control_frame)
        progress_frame.pack(side=tk.RIGHT, fill=tk.X, expand=True, padx=(20, 0))
        
        self.progress = ttk.Progressbar(progress_frame, mode='indeterminate')
        self.progress.pack(fill=tk.X)
        
        self.status_label = ttk.Label(progress_frame, text="å°±ç»ª", foreground="green")
        self.status_label.pack(anchor=tk.W)
        
        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        result_frame = ttk.LabelFrame(main_frame, text="ğŸ“ˆ æ£€æµ‹ç»“æœ")
        result_frame.pack(fill=tk.BOTH, expand=True)
        
        # åˆ›å»ºnotebookç”¨äºæ˜¾ç¤ºä¸åŒç»“æœ
        self.notebook = ttk.Notebook(result_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # æŠ¥å‘Šæ ‡ç­¾é¡µ
        self.create_report_tab()
        
        # å¯è§†åŒ–æ ‡ç­¾é¡µ
        self.create_visualization_tab()
        
        # è¯¦ç»†ç»“æœæ ‡ç­¾é¡µ
        self.create_details_tab()
    
    def create_report_tab(self):
        """åˆ›å»ºæŠ¥å‘Šæ ‡ç­¾é¡µ"""
        self.report_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.report_frame, text="ğŸ“‹ å¯¹æ¯”æŠ¥å‘Š")
        
        # åˆ›å»ºæ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸ
        text_frame = ttk.Frame(self.report_frame)
        text_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # æ–‡æœ¬æ¡†å’Œæ»šåŠ¨æ¡
        self.report_text = tk.Text(text_frame, wrap=tk.WORD, font=('Courier New', 10))
        scrollbar_y = ttk.Scrollbar(text_frame, orient=tk.VERTICAL, command=self.report_text.yview)
        scrollbar_x = ttk.Scrollbar(text_frame, orient=tk.HORIZONTAL, command=self.report_text.xview)
        
        self.report_text.configure(yscrollcommand=scrollbar_y.set, xscrollcommand=scrollbar_x.set)
        
        # å¸ƒå±€
        self.report_text.grid(row=0, column=0, sticky="nsew")
        scrollbar_y.grid(row=0, column=1, sticky="ns")
        scrollbar_x.grid(row=1, column=0, sticky="ew")
        
        text_frame.grid_rowconfigure(0, weight=1)
        text_frame.grid_columnconfigure(0, weight=1)
    
    def create_visualization_tab(self):
        """åˆ›å»ºå¯è§†åŒ–æ ‡ç­¾é¡µ"""
        self.viz_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.viz_frame, text="ğŸ“Š å¯è§†åŒ–ç»“æœ")
        
        # å ä½æ–‡æœ¬
        placeholder_label = ttk.Label(self.viz_frame, text="è¿è¡Œæ£€æµ‹åå°†æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ", 
                                     font=('Arial', 12), foreground="gray")
        placeholder_label.pack(expand=True)
    
    def create_details_tab(self):
        """åˆ›å»ºè¯¦ç»†ç»“æœæ ‡ç­¾é¡µ"""
        self.details_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.details_frame, text="ğŸ” è¯¦ç»†ç»“æœ")
        
        # åˆ›å»ºæ ‘å½¢è§†å›¾æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        tree_frame = ttk.Frame(self.details_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # å®šä¹‰åˆ—
        columns = ('æ–‡ä»¶', 'ç®—æ³•', 'æ‰§è¡Œæ—¶é—´', 'æ£€æµ‹å¼‚å¸¸', 'å‘½ä¸­æ•°', 'å‘½ä¸­ç‡', 'F1åˆ†æ•°')
        self.details_tree = ttk.Treeview(tree_frame, columns=columns, show='tree headings')
        
        # è®¾ç½®åˆ—æ ‡é¢˜å’Œå®½åº¦
        self.details_tree.heading('#0', text='é¡¹ç›®')
        self.details_tree.column('#0', width=100)
        
        for col in columns:
            self.details_tree.heading(col, text=col)
            self.details_tree.column(col, width=100)
        
        # æ»šåŠ¨æ¡
        tree_scrollbar_y = ttk.Scrollbar(tree_frame, orient=tk.VERTICAL, command=self.details_tree.yview)
        tree_scrollbar_x = ttk.Scrollbar(tree_frame, orient=tk.HORIZONTAL, command=self.details_tree.xview)
        
        self.details_tree.configure(yscrollcommand=tree_scrollbar_y.set, xscrollcommand=tree_scrollbar_x.set)
        
        # å¸ƒå±€
        self.details_tree.grid(row=0, column=0, sticky="nsew")
        tree_scrollbar_y.grid(row=0, column=1, sticky="ns")
        tree_scrollbar_x.grid(row=1, column=0, sticky="ew")
        
        tree_frame.grid_rowconfigure(0, weight=1)
        tree_frame.grid_columnconfigure(0, weight=1)
    
    def select_files(self):
        """é€‰æ‹©XDFæ–‡ä»¶"""
        files = filedialog.askopenfilenames(
            title="é€‰æ‹©XDFæ–‡ä»¶",
            filetypes=[("XDF files", "*.xdf"), ("JSON files", "*.json"), ("All files", "*.*")]
        )
        
        if files:
            self.xdf_files = list(files)
            file_names = [os.path.basename(f) for f in files]
            if len(file_names) <= 3:
                display_text = ", ".join(file_names)
            else:
                display_text = f"{', '.join(file_names[:3])} ç­‰ {len(file_names)} ä¸ªæ–‡ä»¶"
            
            self.file_label.config(text=f"å·²é€‰æ‹©: {display_text}", foreground="blue")
            self.status_label.config(text=f"å·²é€‰æ‹© {len(files)} ä¸ªæ–‡ä»¶", foreground="blue")
    
    def clear_files(self):
        """æ¸…ç©ºæ–‡ä»¶åˆ—è¡¨"""
        self.xdf_files = []
        self.file_label.config(text="æœªé€‰æ‹©æ–‡ä»¶", foreground="gray")
        self.status_label.config(text="æ–‡ä»¶åˆ—è¡¨å·²æ¸…ç©º", foreground="orange")
    
    def reset_all(self):
        """é‡ç½®æ‰€æœ‰å†…å®¹"""
        self.clear_files()
        self.report_text.delete(1.0, tk.END)
        self.all_reports = []
        
        # æ¸…ç©ºè¯¦ç»†ç»“æœæ ‘
        for item in self.details_tree.get_children():
            self.details_tree.delete(item)
        
        # æ¸…ç©ºå¯è§†åŒ–
        for widget in self.viz_frame.winfo_children():
            widget.destroy()
        placeholder_label = ttk.Label(self.viz_frame, text="è¿è¡Œæ£€æµ‹åå°†æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ", 
                                     font=('Arial', 12), foreground="gray")
        placeholder_label.pack(expand=True)
        
        self.status_label.config(text="å·²é‡ç½®", foreground="green")
    
    def run_detection_threaded(self):
        """åœ¨çº¿ç¨‹ä¸­è¿è¡Œæ£€æµ‹ï¼Œé¿å…ç•Œé¢å†»ç»“"""
        if not self.xdf_files:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©XDFæ–‡ä»¶")
            return
        
        if not PYOD_AVAILABLE:
            messagebox.showerror("é”™è¯¯", "PyODåº“ä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…PyOD")
            return
        
        # ç¦ç”¨è¿è¡ŒæŒ‰é’®
        self.run_button.config(state='disabled')
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œæ£€æµ‹
        detection_thread = threading.Thread(target=self.run_detection)
        detection_thread.daemon = True
        detection_thread.start()
    
    def run_detection(self):
        """è¿è¡Œå¼‚å¸¸æ£€æµ‹ - åˆå¹¶æ‰€æœ‰æ–‡ä»¶ä¸ºä¸€ä¸ªæ•°æ®é›†"""
        try:
            # æ›´æ–°ç•Œé¢çŠ¶æ€
            self.root.after(0, lambda: self.progress.start())
            self.root.after(0, lambda: self.status_label.config(text="æ­£åœ¨åˆå¹¶æ•°æ®é›†...", foreground="orange"))
            
            # æ¸…ç©ºä¹‹å‰çš„ç»“æœ
            self.root.after(0, lambda: self.report_text.delete(1.0, tk.END))
            self.all_reports = []
            
            # åˆå¹¶æ•°æ®é›†
            combined_features = []
            combined_timestamps = []
            combined_manual_marks = []
            all_file_info = []
            
            # æ·»åŠ æ ‡é¢˜åˆ°æŠ¥å‘Š
            header = f"{'='*80}\n"
            header += f"åˆå¹¶æ•°æ®é›†å¼‚å¸¸æ£€æµ‹ - {len(self.xdf_files)} ä¸ªæ–‡ä»¶\n"
            header += f"{'='*80}\n\n"
            self.root.after(0, lambda text=header: self.append_to_report(text))
            
            # å¤„ç†æ¯ä¸ªæ–‡ä»¶å¹¶åˆå¹¶æ•°æ®
            time_offset = 0.0  # æ—¶é—´åç§»é‡ï¼Œç¡®ä¿æ¯ä¸ªæ–‡ä»¶çš„æ—¶é—´ä¸é‡å 
            
            for i, file_path in enumerate(self.xdf_files):
                self.root.after(0, lambda i=i: self.update_progress_text(f"åŠ è½½æ–‡ä»¶ {i+1}/{len(self.xdf_files)}..."))
                
                file_info = f"ğŸ“ æ–‡ä»¶ {i+1}: {os.path.basename(file_path)}\n"
                self.root.after(0, lambda text=file_info: self.append_to_report(text))
                
                # åŠ è½½æ•°æ®
                if not self.processor.load_xdf_file(file_path):
                    error_msg = f"   âŒ åŠ è½½å¤±è´¥\n\n"
                    self.root.after(0, lambda text=error_msg: self.append_to_report(text))
                    continue
                
                # æå–ç‰¹å¾
                features = self.processor.extract_features()
                if features is None:
                    error_msg = f"   âŒ ç‰¹å¾æå–å¤±è´¥\n\n"
                    self.root.after(0, lambda text=error_msg: self.append_to_report(text))
                    continue
                
                # è°ƒæ•´æ—¶é—´æˆ³ï¼ˆåŠ ä¸Šåç§»é‡é¿å…é‡å ï¼‰
                adjusted_timestamps = self.processor.timestamps + time_offset
                adjusted_manual_marks = [mark + time_offset for mark in self.processor.manual_marks]
                
                # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                info_text = f"   âœ… æ•°æ®ç‚¹: {len(features)}, ç‰¹å¾ç»´åº¦: {features.shape[1]}\n"
                info_text += f"   ğŸ“ æ‰‹åŠ¨æ ‡è®°: {len(self.processor.manual_marks)}ä¸ª\n"
                info_text += f"   â±ï¸  æ—¶é—´èŒƒå›´: {adjusted_timestamps[0]:.2f} - {adjusted_timestamps[-1]:.2f}ç§’\n\n"
                self.root.after(0, lambda text=info_text: self.append_to_report(text))
                
                # åˆå¹¶åˆ°æ€»æ•°æ®é›†
                if len(combined_features) == 0:
                    combined_features = features
                    combined_timestamps = adjusted_timestamps
                else:
                    combined_features = np.vstack([combined_features, features])
                    combined_timestamps = np.concatenate([combined_timestamps, adjusted_timestamps])
                
                combined_manual_marks.extend(adjusted_manual_marks)
                
                # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
                all_file_info.append({
                    'file': os.path.basename(file_path),
                    'file_path': file_path,
                    'data_points': len(features),
                    'manual_marks': len(self.processor.manual_marks),
                    'time_range': (adjusted_timestamps[0], adjusted_timestamps[-1]),
                    'time_offset': time_offset
                })
                
                # æ›´æ–°æ—¶é—´åç§»é‡ï¼ˆä¸‹ä¸€ä¸ªæ–‡ä»¶çš„èµ·å§‹æ—¶é—´ï¼‰
                time_offset = adjusted_timestamps[-1] + 1.0  # åŠ 1ç§’é—´éš”
            
            if len(combined_features) == 0:
                error_msg = "âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶\n"
                self.root.after(0, lambda text=error_msg: self.append_to_report(text))
                return
            
            # æ˜¾ç¤ºåˆå¹¶åçš„æ•°æ®é›†ä¿¡æ¯
            self.root.after(0, lambda: self.status_label.config(text="æ­£åœ¨è¿è¡Œæ£€æµ‹...", foreground="orange"))
            
            combined_info = f"ğŸ”— åˆå¹¶æ•°æ®é›†ä¿¡æ¯:\n"
            combined_info += f"   æ€»æ•°æ®ç‚¹: {len(combined_features)}\n"
            combined_info += f"   ç‰¹å¾ç»´åº¦: {combined_features.shape[1]}\n"
            combined_info += f"   æ€»æ‰‹åŠ¨æ ‡è®°: {len(combined_manual_marks)}ä¸ª\n"
            combined_info += f"   æ€»æ—¶é—´èŒƒå›´: {combined_timestamps[0]:.2f} - {combined_timestamps[-1]:.2f}ç§’\n\n"
            self.root.after(0, lambda text=combined_info: self.append_to_report(text))
            
            # è®¡ç®—contaminationæ¯”ä¾‹
            contamination = min(0.5, max(0.01, len(combined_manual_marks) / len(combined_features)))
            contamination_info = f"ğŸ“Š ç®—æ³•å‚æ•°: contamination = {contamination:.3f} ({len(combined_manual_marks)}/{len(combined_features)})\n\n"
            self.root.after(0, lambda text=contamination_info: self.append_to_report(text))
            
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            self.detector = AnomalyDetectionSuite(contamination=contamination)
            
            # è¿è¡Œå¼‚å¸¸æ£€æµ‹
            self.root.after(0, lambda: self.update_progress_text("æ­£åœ¨è¿è¡Œå¼‚å¸¸æ£€æµ‹ç®—æ³•..."))
            detection_results = self.detector.run_all_algorithms(combined_features)
            
            # ç”ŸæˆæŠ¥å‘Š
            tolerance = self.tolerance_var.get()
            report = self.analyzer.generate_comparison_report(
                detection_results, 
                combined_manual_marks, 
                combined_timestamps
            )
            
            # æ·»åŠ åˆå¹¶ä¿¡æ¯åˆ°æŠ¥å‘Š
            report['tolerance'] = tolerance
            report['file_info'] = all_file_info
            report['combined_dataset'] = True
            
            # ä¿å­˜ç»“æœ
            self.all_reports.append({
                'file': f"åˆå¹¶æ•°æ®é›† ({len(self.xdf_files)}ä¸ªæ–‡ä»¶)",
                'file_path': "combined_dataset",
                'report': report,
                'features': combined_features,
                'detection_results': detection_results,
                'timestamps': combined_timestamps,
                'manual_marks': combined_manual_marks,
                'file_info': all_file_info
            })
            
            # æ˜¾ç¤ºæŠ¥å‘Š
            self.display_single_report(report)
            
            # æ›´æ–°è¯¦ç»†ç»“æœæ ‘
            self.root.after(0, self.update_details_tree)
            
            # åˆ›å»ºå¯è§†åŒ–
            self.root.after(0, self.create_visualizations)
            
            # ç”Ÿæˆæ¨ªå‘å¯¹æ¯”æŠ¥å‘Šï¼ˆæŒ‰ç…§å‚è€ƒå›¾ç‰‡æ ¼å¼ï¼‰
            self.root.after(0, self.generate_horizontal_comparison_report)
            
        except Exception as e:
            error_msg = f"æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", error_msg))
            print(f"âŒ æ£€æµ‹å¤±è´¥: {e}")
        finally:
            # æ¢å¤ç•Œé¢çŠ¶æ€
            self.root.after(0, lambda: self.progress.stop())
            self.root.after(0, lambda: self.status_label.config(text="æ£€æµ‹å®Œæˆ", foreground="green"))
            self.root.after(0, lambda: self.run_button.config(state='normal'))
    
    def update_progress_text(self, text):
        """æ›´æ–°è¿›åº¦æ–‡æœ¬"""
        self.status_label.config(text=text, foreground="orange")
    
    def append_to_report(self, text):
        """å‘æŠ¥å‘Šæ·»åŠ æ–‡æœ¬"""
        self.report_text.insert(tk.END, text)
        self.report_text.see(tk.END)
        self.report_text.update()
    
    def display_single_report(self, report):
        """æ˜¾ç¤ºå•ä¸ªæ–‡ä»¶çš„æŠ¥å‘Š - ä½¿ç”¨æ–°çš„æŠ¥å‘Šæ ¼å¼å’Œå¯è§†åŒ–"""
        def update_ui():
            # è·å–æŠ¥å‘Šç”Ÿæˆå™¨
            report_generator = ReportGenerator()
            
            # è·å–å½“å‰æŠ¥å‘Šå¯¹åº”çš„æ•°æ®ï¼ˆä»all_reportsè·å–æ­£ç¡®çš„æ•°æ®ï¼‰
            current_report_data = None
            if self.all_reports:
                current_report_data = self.all_reports[-1]  # æœ€æ–°çš„æŠ¥å‘Šæ•°æ®
            
            # ç”Ÿæˆæ¯ä¸ªç®—æ³•çš„è¯¦ç»†æŠ¥å‘Šå’Œå¯è§†åŒ–
            for algo_name, result in report['algorithms'].items():
                if 'error' in result:
                    continue
                    
                # è·å–éœ€è¦çš„æ•°æ®
                if 'predictions' not in result or 'scores' not in result:
                    # å¦‚æœæ²¡æœ‰åŸå§‹æ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–
                    self.report_text.insert(tk.END, f"\n{algo_name} ç®—æ³•ç»“æœï¼ˆæ— è¯¦ç»†æ•°æ®ï¼‰:\n")
                    self.report_text.insert(tk.END, f"  å‘½ä¸­ç‡: {result.get('hit_rate', 0):.1f}%\n")
                    self.report_text.insert(tk.END, f"  æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.3f}ç§’\n\n")
                    continue
                
                predictions = result['predictions']
                scores = result['scores'] 
                
                # ä½¿ç”¨åˆå¹¶åçš„æ•°æ®è€Œä¸æ˜¯å•ä¸ªæ–‡ä»¶çš„æ•°æ®
                if current_report_data:
                    manual_marks = current_report_data['manual_marks']
                    timestamps = current_report_data['timestamps']
                    va_data = current_report_data['features'][:, :2]  # åªå–VAç»´åº¦
                else:
                    # åå¤‡é€‰é¡¹
                    manual_marks = self.processor.manual_marks
                    timestamps = self.processor.timestamps
                    va_data = self.processor.va_data
                
                execution_time = result['execution_time']
                hit_rate = result['hit_rate']
                precision = result['precision']
                recall = result['recall']
                f1 = result['f1_score']
                detected_anomalies = result.get('anomaly_indices', [])
                
                # è¿‡æ»¤æœ‰æ•ˆçš„å¼‚å¸¸ç´¢å¼•ï¼Œç¡®ä¿ä¸è¶…å‡ºæ•°æ®èŒƒå›´
                valid_anomalies = [idx for idx in detected_anomalies if 0 <= idx < len(timestamps)]
                
                # ç”Ÿæˆä¸ªä½“æŠ¥å‘Š
                individual_report = report_generator.generate_individual_report(
                    algo_name, predictions, scores, manual_marks, timestamps,
                    execution_time, hit_rate, precision, recall, f1
                )
                
                # æ·»åŠ åˆ°UI
                self.report_text.insert(tk.END, individual_report)
                
                # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ - ä½¿ç”¨è¿‡æ»¤åçš„ç´¢å¼•
                if algo_name == "IsolationForest":
                    # ä¸ºIsolationForestç”Ÿæˆç‰¹æ®Šçš„å¯è§†åŒ–
                    isolationforest_viz = IsolationForestVisualizer()
                    fig = isolationforest_viz.create_visualization(
                        va_data, timestamps, predictions, scores,
                        manual_marks, valid_anomalies, hit_rate
                    )
                else:
                    fig = self.visualizer.plot_single_algorithm_result(
                        algo_name, va_data, timestamps, predictions, scores,
                        manual_marks, valid_anomalies, hit_rate
                    )
                
                if fig:
                    # åœ¨GUIä¸­æ˜¾ç¤ºå›¾è¡¨ï¼ˆå¯ä»¥ä¿å­˜ä¸ºå›¾ç‰‡æˆ–åµŒå…¥ï¼‰
                    import os
                    import tempfile
                    temp_dir = tempfile.gettempdir()
                    fig_path = os.path.join(temp_dir, f"{algo_name}_result.png")
                    fig.savefig(fig_path, dpi=100, bbox_inches='tight')
                    plt.close(fig)  # ä½¿ç”¨plt.close()è€Œä¸æ˜¯fig.close()
                    
                    # åœ¨æŠ¥å‘Šä¸­æ·»åŠ å›¾ç‰‡è·¯å¾„ä¿¡æ¯
                    self.report_text.insert(tk.END, f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {fig_path}\n\n")
            
            self.report_text.see(tk.END)
            self.report_text.update()
        
        self.root.after(0, update_ui)

    def display_summary_report(self):
        """æ˜¾ç¤ºæ±‡æ€»æŠ¥å‘Š - ä½¿ç”¨æ–°çš„å¯¹æ¯”æŠ¥å‘Šæ ¼å¼å’Œå¯è§†åŒ–"""
        def update_ui():
            # è·å–æŠ¥å‘Šç”Ÿæˆå™¨
            report_generator = ReportGenerator()
            
            # åˆå¹¶æ‰€æœ‰ç®—æ³•ç»“æœ
            combined_results = {}
            total_manual_marks = 0
            
            for report_data in self.all_reports:
                report = report_data['report']
                manual_marks = self.processor.manual_marks if hasattr(self, 'processor') else []
                total_manual_marks += len(manual_marks)
                
                for algo_name, result in report['algorithms'].items():
                    if algo_name not in combined_results:
                        combined_results[algo_name] = {
                            'hit_rate': 0,
                            'execution_time': 0,
                            'detected_anomalies': 0,
                            'count': 0
                        }
                    
                    combined_results[algo_name]['hit_rate'] += result['hit_rate']
                    combined_results[algo_name]['execution_time'] += result['execution_time'] 
                    combined_results[algo_name]['detected_anomalies'] += result.get('total_anomalies_detected', 0)
                    combined_results[algo_name]['count'] += 1
            
            # è®¡ç®—å¹³å‡å€¼
            for algo_name in combined_results:
                count = combined_results[algo_name]['count']
                combined_results[algo_name]['hit_rate'] /= count
                combined_results[algo_name]['execution_time'] /= count
                combined_results[algo_name]['detected_anomalies'] = int(combined_results[algo_name]['detected_anomalies'] / count)
            
            # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
            avg_manual_marks = total_manual_marks // len(self.all_reports) if self.all_reports else 0
            comparison_report = report_generator.generate_comparison_report(
                combined_results, 
                list(range(avg_manual_marks))  # ä¼°ç®—å¹³å‡æ‰‹åŠ¨æ ‡è®°æ•°
            )
            
            # æ·»åŠ åˆ°UI
            self.report_text.insert(tk.END, comparison_report)
            
            # ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–
            fig = self.visualizer.plot_algorithms_comparison(combined_results, avg_manual_marks)
            
            if fig:
                # ä¿å­˜å¯¹æ¯”å›¾è¡¨
                import os
                import tempfile
                temp_dir = tempfile.gettempdir()
                fig_path = os.path.join(temp_dir, "algorithms_comparison.png")
                fig.savefig(fig_path, dpi=150, bbox_inches='tight')
                fig.close()
                
                # åœ¨æŠ¥å‘Šä¸­æ·»åŠ å›¾ç‰‡è·¯å¾„ä¿¡æ¯
                self.report_text.insert(tk.END, f"\nğŸ“Š ç®—æ³•å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {fig_path}\n")
                
                # å°è¯•æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¦‚æœæ”¯æŒï¼‰
                try:
                    import os
                    os.startfile(fig_path)  # Windows
                except:
                    try:
                        import subprocess
                        subprocess.run(['open', fig_path])  # macOS
                    except:
                        try:
                            subprocess.run(['xdg-open', fig_path])  # Linux
                        except:
                            pass
            
            self.report_text.see(tk.END)
            self.report_text.update()
        
        self.root.after(0, update_ui)
    
    def update_details_tree(self):
        """æ›´æ–°è¯¦ç»†ç»“æœæ ‘"""
        # æ¸…ç©ºç°æœ‰å†…å®¹
        for item in self.details_tree.get_children():
            self.details_tree.delete(item)
        
        # æ·»åŠ æ•°æ®
        for i, report_data in enumerate(self.all_reports):
            file_name = report_data['file']
            report = report_data['report']
            
            # æ’å…¥æ–‡ä»¶èŠ‚ç‚¹
            file_item = self.details_tree.insert('', 'end', text=f"æ–‡ä»¶ {i+1}", 
                                                 values=(file_name, '', '', '', '', '', ''))
            
            # æ’å…¥ç®—æ³•ç»“æœ
            for alg_name, metrics in report['algorithms'].items():
                self.details_tree.insert(file_item, 'end', text='', 
                                        values=('', alg_name, 
                                               f"{metrics['execution_time']:.3f}",
                                               f"{metrics['total_anomalies_detected']}",
                                               f"{metrics['manual_marks_hit']}",
                                               f"{metrics['hit_rate']:.3f}",
                                               f"{metrics['f1_score']:.3f}"))
        
        # å±•å¼€æ‰€æœ‰èŠ‚ç‚¹
        for item in self.details_tree.get_children():
            self.details_tree.item(item, open=True)
    
    def create_visualizations(self):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        # æ¸…ç©ºç°æœ‰å†…å®¹
        for widget in self.viz_frame.winfo_children():
            widget.destroy()
        
        if not self.all_reports:
            return
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle('PyODå¼‚å¸¸æ£€æµ‹ç»“æœåˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. ç®—æ³•æ€§èƒ½å¯¹æ¯”ï¼ˆå‘½ä¸­ç‡ï¼‰
        self.plot_hit_rate_comparison(axes[0, 0])
        
        # 2. æ‰§è¡Œæ—¶é—´å¯¹æ¯”
        self.plot_execution_time_comparison(axes[0, 1])
        
        # 3. F1åˆ†æ•°å¯¹æ¯”
        self.plot_f1_score_comparison(axes[1, 0])
        
        # 4. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
        self.plot_performance_radar(axes[1, 1])
        
        plt.tight_layout()
        
        # å°†å›¾è¡¨åµŒå…¥åˆ°tkinterä¸­
        canvas = FigureCanvasTkAgg(fig, self.viz_frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def generate_horizontal_comparison_report(self):
        """ç”Ÿæˆä¸¥æ ¼æŒ‰ç…§å‚è€ƒå›¾ç‰‡æ ¼å¼çš„æ¨ªå‘å¯¹æ¯”æŠ¥å‘Š"""
        if not self.all_reports:
            return
        
        try:
            # ä»æŠ¥å‘Šä¸­æå–æ•°æ®
            current_report = self.all_reports[-1]['report']
            algorithms_data = current_report['algorithms']
            total_manual_marks = current_report['summary']['total_manual_marks']
            
            # ç®—æ³•åç§°æ˜ å°„
            algo_name_mapping = {
                'ECOD': 'ECOD',
                'IsolationForest': 'IForest', 
                'PCA': 'PCA',
                'MCD': 'MCD',
                'GMM': 'GMM'
            }
            
            # æå–æ€§èƒ½æ•°æ®
            algorithms = []
            hit_rates = []
            execution_times = []
            hit_counts = []
            
            for algo_name, metrics in algorithms_data.items():
                if 'error' not in metrics:
                    display_name = algo_name_mapping.get(algo_name, algo_name)
                    algorithms.append(display_name)
                    hit_rates.append(metrics['hit_rate'])
                    execution_times.append(metrics['execution_time'])
                    
                    # è®¡ç®—å‘½ä¸­æ•°é‡
                    hit_count = int(round(metrics['hit_rate'] * total_manual_marks / 100))
                    hit_counts.append(hit_count)
            
            if not algorithms:
                return
            
            # æŒ‰å‘½ä¸­ç‡æ’åºï¼ˆä»ä½åˆ°é«˜ï¼‰
            sorted_indices = np.argsort(hit_rates)
            algorithms = [algorithms[i] for i in sorted_indices]
            hit_rates = [hit_rates[i] for i in sorted_indices]
            execution_times = [execution_times[i] for i in sorted_indices]
            hit_counts = [hit_counts[i] for i in sorted_indices]
            
            # åˆ›å»ºæ¨ªå‘å¯¹æ¯”å›¾è¡¨
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
            fig.suptitle(f'åˆå¹¶æ•°æ®é›†PyODç®—æ³•æ€§èƒ½å¯¹æ¯” (æ€»æ ‡æ³¨å¼‚å¸¸: {total_manual_marks}ä¸ª, å®¹å·®: Â±1.0s)', 
                         fontsize=16, fontweight='bold')
            
            # å·¦å›¾ï¼šå¼‚å¸¸æ£€æµ‹å¬å›ç‡
            y_pos = np.arange(len(algorithms))
            bars1 = ax1.barh(y_pos, hit_rates, color='steelblue', alpha=0.8, height=0.6)
            
            # åœ¨æ¯ä¸ªæŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, hit_count) in enumerate(zip(bars1, hit_counts)):
                width = bar.get_width()
                ax1.text(width + 1, bar.get_y() + bar.get_height()/2, 
                        f'{hit_count}/{total_manual_marks}', ha='left', va='center', 
                        fontsize=10, fontweight='bold')
            
            ax1.set_yticks(y_pos)
            ax1.set_yticklabels(algorithms, fontsize=11)
            ax1.set_xlabel('å¬å›ç‡ (%)', fontsize=12, fontweight='bold')
            ax1.set_title('å¼‚å¸¸æ£€æµ‹å¬å›ç‡', fontsize=14, fontweight='bold')
            ax1.set_xlim(0, 100)
            ax1.grid(True, axis='x', alpha=0.3)
            ax1.set_axisbelow(True)
            
            # æ·»åŠ ç½‘æ ¼çº¿
            for i in range(0, 101, 20):
                ax1.axvline(x=i, color='gray', linestyle='-', alpha=0.3, linewidth=0.5)
            
            # å³å›¾ï¼šç®—æ³•è®­ç»ƒæ—¶é—´ï¼ˆå¯¹æ•°åˆ»åº¦ï¼‰
            bars2 = ax2.barh(y_pos, execution_times, color='chocolate', alpha=0.8, height=0.6)
            
            # åœ¨æ¯ä¸ªæŸ±å­ä¸Šæ·»åŠ æ—¶é—´æ ‡ç­¾
            for bar, exec_time in zip(bars2, execution_times):
                width = bar.get_width()
                if exec_time < 0.01:
                    time_label = f'{exec_time*1000:.1f}ms'
                else:
                    time_label = f'{exec_time:.2f}s'
                ax2.text(width * 1.1, bar.get_y() + bar.get_height()/2, 
                        time_label, ha='left', va='center', fontsize=10, fontweight='bold')
            
            ax2.set_yticks(y_pos)
            ax2.set_yticklabels(algorithms, fontsize=11)
            ax2.set_xlabel('è®­ç»ƒæ—¶é—´ (ç§’)', fontsize=12, fontweight='bold')
            ax2.set_title('ç®—æ³•è®­ç»ƒæ—¶é—´', fontsize=14, fontweight='bold')
            ax2.set_xscale('log')  # å¯¹æ•°åˆ»åº¦
            ax2.grid(True, axis='x', alpha=0.3)
            ax2.set_axisbelow(True)
            ax2.set_xlim(0.001, max(execution_times) * 2)
            
            plt.tight_layout()
            
            # ä¿å­˜æ¨ªå‘å¯¹æ¯”æŠ¥å‘Š
            import tempfile
            temp_dir = tempfile.gettempdir()
            report_path = os.path.join(temp_dir, "PyOD_Horizontal_Comparison_Report.png")
            fig.savefig(report_path, dpi=150, bbox_inches='tight', facecolor='white')
            
            # å…³é—­å›¾è¡¨é‡Šæ”¾å†…å­˜
            plt.close(fig)
            
            # åœ¨æŠ¥å‘Šæ–‡æœ¬åŒºåŸŸæ·»åŠ ä¿¡æ¯
            report_info = f"\nğŸ“Š æ¨ªå‘å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}\n"
            report_info += "="*60 + "\n"
            report_info += f"{'ç®—æ³•':<12} {'å‘½ä¸­ç‡':<8} {'å‘½ä¸­æ•°':<8} {'æ‰§è¡Œæ—¶é—´':<10}\n"
            report_info += "-"*60 + "\n"
            
            for i, algo in enumerate(algorithms):
                hit_rate = hit_rates[i]
                hit_count = hit_counts[i]
                exec_time = execution_times[i]
                time_str = f"{exec_time:.3f}s" if exec_time >= 0.001 else f"{exec_time*1000:.1f}ms"
                report_info += f"{algo:<12} {hit_rate:>6.1f}% {hit_count:>3}/{total_manual_marks:<3} {time_str:>8}\n"
            
            report_info += "="*60 + "\n\n"
            
            self.report_text.insert(tk.END, report_info)
            self.report_text.see(tk.END)
            
            print(f"ğŸ“Š æ¨ªå‘å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆæ¨ªå‘å¯¹æ¯”æŠ¥å‘Šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def plot_hit_rate_comparison(self, ax):
        """ç»˜åˆ¶å‘½ä¸­ç‡å¯¹æ¯”å›¾"""
        if not self.all_reports:
            return
        
        # æ”¶é›†æ•°æ®
        algorithms = set()
        for report_data in self.all_reports:
            algorithms.update(report_data['report']['algorithms'].keys())
        
        algorithms = list(algorithms)
        hit_rates = {alg: [] for alg in algorithms}
        
        for report_data in self.all_reports:
            for alg in algorithms:
                if alg in report_data['report']['algorithms']:
                    hit_rates[alg].append(report_data['report']['algorithms'][alg]['hit_rate'])
                else:
                    hit_rates[alg].append(0)
        
        # ç»˜åˆ¶ç®±çº¿å›¾
        data_to_plot = [hit_rates[alg] for alg in algorithms]
        bp = ax.boxplot(data_to_plot, labels=algorithms, patch_artist=True)
        
        # è®¾ç½®é¢œè‰²
        colors = plt.cm.Set3(np.linspace(0, 1, len(algorithms)))
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
        
        ax.set_title('å‘½ä¸­ç‡å¯¹æ¯”')
        ax.set_ylabel('å‘½ä¸­ç‡')
        ax.grid(True, alpha=0.3)
        plt.setp(ax.get_xticklabels(), rotation=45)
    
    def plot_execution_time_comparison(self, ax):
        """ç»˜åˆ¶æ‰§è¡Œæ—¶é—´å¯¹æ¯”å›¾"""
        if not self.all_reports:
            return
        
        # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´
        algorithms = set()
        for report_data in self.all_reports:
            algorithms.update(report_data['report']['algorithms'].keys())
        
        algorithms = list(algorithms)
        avg_times = []
        
        for alg in algorithms:
            times = []
            for report_data in self.all_reports:
                if alg in report_data['report']['algorithms']:
                    times.append(report_data['report']['algorithms'][alg]['execution_time'])
            avg_times.append(np.mean(times) if times else 0)
        
        # ç»˜åˆ¶æ¡å½¢å›¾
        bars = ax.bar(algorithms, avg_times, color=plt.cm.Set2(np.linspace(0, 1, len(algorithms))))
        
        ax.set_title('å¹³å‡æ‰§è¡Œæ—¶é—´å¯¹æ¯”')
        ax.set_ylabel('æ‰§è¡Œæ—¶é—´ (ç§’)')
        ax.grid(True, alpha=0.3)
        plt.setp(ax.get_xticklabels(), rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, time in zip(bars, avg_times):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                   f'{time:.3f}s', ha='center', va='bottom', fontsize=8)
    
    def plot_f1_score_comparison(self, ax):
        """ç»˜åˆ¶F1åˆ†æ•°å¯¹æ¯”å›¾"""
        if not self.all_reports:
            return
        
        # æ”¶é›†æ•°æ®
        algorithms = set()
        for report_data in self.all_reports:
            algorithms.update(report_data['report']['algorithms'].keys())
        
        algorithms = list(algorithms)
        f1_scores = {alg: [] for alg in algorithms}
        
        for report_data in self.all_reports:
            for alg in algorithms:
                if alg in report_data['report']['algorithms']:
                    f1_scores[alg].append(report_data['report']['algorithms'][alg]['f1_score'])
                else:
                    f1_scores[alg].append(0)
        
        # ç»˜åˆ¶å°æç´å›¾
        data_to_plot = [f1_scores[alg] for alg in algorithms]
        vp = ax.violinplot(data_to_plot, positions=range(len(algorithms)), showmeans=True)
        
        ax.set_title('F1åˆ†æ•°åˆ†å¸ƒ')
        ax.set_ylabel('F1åˆ†æ•°')
        ax.set_xticks(range(len(algorithms)))
        ax.set_xticklabels(algorithms, rotation=45)
        ax.grid(True, alpha=0.3)
    
    def plot_performance_radar(self, ax):
        """ç»˜åˆ¶æ€§èƒ½é›·è¾¾å›¾"""
        if not self.all_reports:
            return
        
        # è®¡ç®—æ¯ä¸ªç®—æ³•çš„å¹³å‡æ€§èƒ½æŒ‡æ ‡
        algorithms = set()
        for report_data in self.all_reports:
            algorithms.update(report_data['report']['algorithms'].keys())
        
        algorithms = list(algorithms)
        
        # æ€§èƒ½æŒ‡æ ‡ï¼šå‘½ä¸­ç‡ã€ç²¾ç¡®ç‡ã€F1åˆ†æ•°ã€é€Ÿåº¦ï¼ˆ1/æ‰§è¡Œæ—¶é—´ï¼‰
        metrics = ['å‘½ä¸­ç‡', 'ç²¾ç¡®ç‡', 'F1åˆ†æ•°', 'é€Ÿåº¦']
        
        # è®¡ç®—æ¯ä¸ªç®—æ³•çš„å¹³å‡å€¼
        perf_data = {}
        for alg in algorithms:
            hit_rates = []
            precisions = []
            f1_scores = []
            exec_times = []
            
            for report_data in self.all_reports:
                if alg in report_data['report']['algorithms']:
                    alg_metrics = report_data['report']['algorithms'][alg]
                    hit_rates.append(alg_metrics['hit_rate'])
                    precisions.append(alg_metrics['precision'])
                    f1_scores.append(alg_metrics['f1_score'])
                    exec_times.append(alg_metrics['execution_time'])
            
            if hit_rates:  # å¦‚æœæœ‰æ•°æ®
                avg_hit_rate = np.mean(hit_rates)
                avg_precision = np.mean(precisions)
                avg_f1 = np.mean(f1_scores)
                avg_speed = 1 / np.mean(exec_times) if np.mean(exec_times) > 0 else 0
                
                # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
                perf_data[alg] = [avg_hit_rate, avg_precision, avg_f1, avg_speed]
        
        if not perf_data:
            ax.text(0.5, 0.5, 'æ— å¯è§†åŒ–æ•°æ®', ha='center', va='center', transform=ax.transAxes)
            return
        
        # å½’ä¸€åŒ–é€Ÿåº¦æŒ‡æ ‡
        all_speeds = [data[3] for data in perf_data.values()]
        max_speed = max(all_speeds) if all_speeds else 1
        for alg in perf_data:
            perf_data[alg][3] = perf_data[alg][3] / max_speed if max_speed > 0 else 0
        
        # è®¾ç½®é›·è¾¾å›¾
        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ
        
        ax.clear()
        
        # ç»˜åˆ¶æ¯ä¸ªç®—æ³•
        colors = plt.cm.Set1(np.linspace(0, 1, len(algorithms)))
        for i, (alg, data) in enumerate(perf_data.items()):
            values = data + data[:1]  # é—­åˆ
            ax.plot(angles, values, 'o-', linewidth=2, label=alg, color=colors[i])
            ax.fill(angles, values, alpha=0.1, color=colors[i])
        
        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metrics)
        ax.set_ylim(0, 1)
        ax.set_title('ç»¼åˆæ€§èƒ½é›·è¾¾å›¾')
        ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))
        ax.grid(True)
    
    def export_report(self):
        """å¯¼å‡ºæŠ¥å‘Š"""
        content = self.report_text.get(1.0, tk.END)
        if not content.strip():
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯å¯¼å‡ºçš„æŠ¥å‘Š")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="ä¿å­˜æŠ¥å‘Š",
            defaultextension=".txt",
            filetypes=[("Text files", "*.txt"), ("All files", "*.*")]
        )
        
        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(f"PyODå¼‚å¸¸æ£€æµ‹å¯¹æ¯”æŠ¥å‘Š\n")
                    f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"å·¥å…·ç‰ˆæœ¬: v1.0\n")
                    f.write(f"å¤„ç†æ–‡ä»¶æ•°: {len(self.all_reports)}\n")
                    f.write(f"{'='*80}\n\n")
                    f.write(content)
                    
                    # æ·»åŠ è¯¦ç»†çš„ç®—æ³•å‚æ•°ä¿¡æ¯
                    f.write(f"\n\n{'='*80}\n")
                    f.write(f"ç®—æ³•å‚æ•°è®¾ç½®:\n")
                    f.write(f"{'='*80}\n")
                    f.write(f"å¼‚å¸¸æ£€æµ‹æ¨¡å¼: ä½¿ç”¨å„ç®—æ³•é»˜è®¤å‚æ•°\n")
                    f.write(f"å®¹å·®æ—¶é—´ (tolerance): {self.tolerance_var.get()}ç§’\n")
                    f.write(f"éšæœºç§å­ (random_state): 42\n")
                
                messagebox.showinfo("æˆåŠŸ", f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {file_path}")
                self.status_label.config(text=f"æŠ¥å‘Šå·²å¯¼å‡º: {os.path.basename(file_path)}", foreground="green")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡ŒGUI"""
        self.root.mainloop()

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–é¡¹"""
    missing_deps = []
    
    try:
        import numpy
    except ImportError:
        missing_deps.append("numpy")
    
    try:
        import pandas
    except ImportError:
        missing_deps.append("pandas")
    
    try:
        import matplotlib
    except ImportError:
        missing_deps.append("matplotlib")
    
    try:
        import seaborn
    except ImportError:
        missing_deps.append("seaborn")
    
    if not PYOD_AVAILABLE:
        missing_deps.append("pyod")
    
    if missing_deps:
        print("âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–é¡¹:")
        for dep in missing_deps:
            print(f"   - {dep}")
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print(f"pip install {' '.join(missing_deps)}")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–é¡¹å·²å®‰è£…")
    return True

class IsolationForestVisualizer:
    """ä¸“é—¨ä¸ºIsolationForeståˆ›å»ºå¯è§†åŒ–çš„ç±»"""
    
    def __init__(self):
        self.plt_available = plt is not None
    
    def create_visualization(self, va_data, timestamps, predictions, scores, 
                           manual_marks, detected_anomalies, hit_rate):
        """ä¸ºIsolationForeståˆ›å»ºä¸“é—¨çš„å¯è§†åŒ–å›¾è¡¨ - æŒ‰ç…§å‚è€ƒå›¾ç‰‡æ ¼å¼"""
        if not self.plt_available:
            return None
            
        try:
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))
            fig.suptitle('VAæ•°æ®: æ‰‹åŠ¨æ ‡æ³¨ vs IsolationForestæ£€æµ‹ç»“æœå¯¹æ¯”', fontsize=16, fontweight='bold')
            
            # ä¸Šå›¾ï¼šVAæ•°æ®æ—¶é—´åºåˆ—ï¼ˆä»¿ç…§GSRæ•°æ®æ ¼å¼ï¼‰
            # ç»˜åˆ¶Valenceæ•°æ®ä½œä¸ºä¸»è¦ä¿¡å·
            ax1.plot(timestamps, va_data[:, 0], 'b-', alpha=0.8, linewidth=1.2, label='Valence')
            
            # æ ‡è®°æ‰‹åŠ¨å¼‚å¸¸ç‚¹ - ç»¿è‰²æ–¹å—ï¼ˆä¸¥æ ¼æŒ‰ç…§å‚è€ƒå›¾ç‰‡ï¼‰
            manual_y_positions = []
            if len(manual_marks) > 0:
                for i, mark_time in enumerate(manual_marks):
                    # æ‰¾åˆ°æœ€æ¥è¿‘çš„æ—¶é—´ç‚¹
                    time_diffs = np.abs(timestamps - mark_time)
                    closest_idx = np.argmin(time_diffs)
                    
                    if closest_idx < len(va_data):
                        y_pos = va_data[closest_idx, 0]  # Valenceå€¼
                        manual_y_positions.append(y_pos)
                        
                        # ç»¿è‰²æ–¹å—æ ‡è®°
                        ax1.scatter([mark_time], [y_pos], 
                                  c='green', s=120, marker='s', 
                                  label='æ‰‹åŠ¨æ ‡æ³¨å¼‚å¸¸ç‚¹' if i == 0 else "", 
                                  zorder=15, edgecolors='darkgreen', linewidth=1.5, alpha=0.9)
            
            # æ ‡è®°ç®—æ³•æ£€æµ‹å¼‚å¸¸ç‚¹ - çº¢è‰²åœ†ç‚¹
            detected_y_positions = []
            if len(detected_anomalies) > 0:
                valid_anomalies = [idx for idx in detected_anomalies if 0 <= idx < len(timestamps) and 0 <= idx < len(va_data)]
                if valid_anomalies:
                    detected_times = timestamps[valid_anomalies]
                    detected_y_vals = va_data[valid_anomalies, 0]  # Valenceå€¼
                    
                    # çº¢è‰²åœ†ç‚¹æ ‡è®°
                    ax1.scatter(detected_times, detected_y_vals, 
                              c='red', s=80, marker='o', alpha=0.8,
                              label='ç®—æ³•æ£€æµ‹å¼‚å¸¸ç‚¹', zorder=12, edgecolors='darkred', linewidth=1)
                    detected_y_positions = detected_y_vals
            
            # è®¾ç½®åæ ‡è½´
            ax1.set_xlabel('Time Index', fontsize=12)
            ax1.set_ylabel('VA (Valence)', fontsize=12)
            # è®¡ç®—å®é™…å‘½ä¸­æ•°é‡
            hit_count = int(round(hit_rate * len(manual_marks) / 100))
            ax1.set_title(f'å‘½ä¸­æƒ…å†µ: {hit_count}/{len(manual_marks)} = {hit_rate:.1f}%', 
                         fontsize=14, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
            ax1.grid(True, alpha=0.3)
            ax1.legend(loc='upper left', fontsize=11)
            
            # ä¸‹å›¾ï¼šå¼‚å¸¸åˆ†æ•°æ—¶é—´åºåˆ—ï¼ˆä»¿ç…§COPOD Anomaly Scoresæ ¼å¼ï¼‰
            # åˆ†æ®µç»˜åˆ¶å¼‚å¸¸åˆ†æ•°ï¼ˆå‚è€ƒå›¾ç‰‡æ˜¾ç¤ºçš„åˆ†æ®µæ•ˆæœï¼‰
            mid_point = len(timestamps) // 2
            
            # å‰åŠæ®µ - ç»¿è‰²
            ax2.plot(timestamps[:mid_point], scores[:mid_point], 
                    color='green', alpha=0.8, linewidth=1.5, label='Train Scores')
            
            # ååŠæ®µ - ç´«è‰²
            ax2.plot(timestamps[mid_point:], scores[mid_point:], 
                    color='purple', alpha=0.8, linewidth=1.5, label='Test Scores')
            
            # åœ¨å¼‚å¸¸åˆ†æ•°å›¾ä¸Šæ ‡è®°æ‰‹åŠ¨å¼‚å¸¸ç‚¹ - ç»¿è‰²æ–¹å—
            if len(manual_marks) > 0:
                for i, mark_time in enumerate(manual_marks):
                    time_diffs = np.abs(timestamps - mark_time)
                    closest_idx = np.argmin(time_diffs)
                    
                    if closest_idx < len(scores):
                        y_pos = scores[closest_idx]
                        ax2.scatter([mark_time], [y_pos], 
                                  c='green', s=120, marker='s', 
                                  label='æ‰‹åŠ¨æ ‡æ³¨çš„å¼‚å¸¸åˆ†æ•°' if i == 0 else "", 
                                  zorder=15, edgecolors='darkgreen', linewidth=1.5, alpha=0.9)
            
            # æ ‡è®°ç®—æ³•æ£€æµ‹çš„å¼‚å¸¸åˆ†æ•°
            if len(detected_anomalies) > 0:
                valid_anomalies = [idx for idx in detected_anomalies if 0 <= idx < len(timestamps) and 0 <= idx < len(scores)]
                if valid_anomalies:
                    detected_times = timestamps[valid_anomalies]
                    detected_scores = scores[valid_anomalies]
                    ax2.scatter(detected_times, detected_scores, 
                               c='red', s=80, marker='o', alpha=0.8,
                               label='æ£€æµ‹å¼‚å¸¸åˆ†æ•°', zorder=12, edgecolors='darkred', linewidth=1)
            
            # æ·»åŠ åˆ†å‰²çº¿ï¼ˆå‚è€ƒå›¾ç‰‡çš„Train/Test Splitï¼‰
            split_time = timestamps[mid_point]
            ax1.axvline(x=split_time, color='gray', linestyle='--', alpha=0.6, linewidth=2)
            ax2.axvline(x=split_time, color='gray', linestyle='--', alpha=0.6, linewidth=2, label='Train/Test Split')
            
            ax2.set_xlabel('Time Index', fontsize=12)
            ax2.set_ylabel('Anomaly Score', fontsize=12)
            ax2.set_title('IsolationForest å¼‚å¸¸åˆ†æ•°', fontsize=14)
            ax2.legend(loc='upper left', fontsize=11)
            ax2.grid(True, alpha=0.3)
            
            # åˆ›å»ºå³ä¾§å›¾ä¾‹ï¼ˆä»¿ç…§å‚è€ƒå›¾ç‰‡ï¼‰
            legend_elements = [
                plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='green', 
                          markersize=10, label=f'æ‰‹åŠ¨æ ‡æ³¨å¼‚å¸¸ç‚¹ ({len(manual_marks)})'),
                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', 
                          markersize=8, label=f'ç®—æ³•æ£€æµ‹å¼‚å¸¸ç‚¹ ({len(detected_anomalies)})'),
                plt.Line2D([0], [0], color='blue', linewidth=2, label='Valenceæ•°æ®'),
                plt.Line2D([0], [0], color='green', linewidth=2, label='Trainé˜¶æ®µåˆ†æ•°'),
                plt.Line2D([0], [0], color='purple', linewidth=2, label='Testé˜¶æ®µåˆ†æ•°'),
                plt.Line2D([0], [0], color='gray', linestyle='--', linewidth=2, label='Train/Teståˆ†å‰²çº¿')
            ]
            
            # å³ä¾§å›¾ä¾‹
            fig.legend(handles=legend_elements, loc='center right', 
                      bbox_to_anchor=(0.98, 0.5), fontsize=10,
                      title='VA Data', title_fontsize=12)
            
            plt.tight_layout()
            plt.subplots_adjust(right=0.82)  # ä¸ºå³ä¾§å›¾ä¾‹é¢„ç•™ç©ºé—´
            
            return fig
            
        except Exception as e:
            print(f"âš ï¸ IsolationForestå¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨PyODå¼‚å¸¸æ£€æµ‹å¯¹æ¯”å·¥å…·...")
    print("="*50)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        input("æŒ‰Enteré”®é€€å‡º...")
        return
    
    try:
        app = PyODAnomalyGUI()
        app.run()
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
        input("æŒ‰Enteré”®é€€å‡º...")

if __name__ == "__main__":
    main()